{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from datasets import load_dataset\n",
    "from gpt4all import GPT4All\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding vector\n",
    "class VectorStore:\n",
    "    def __init__(self, collection_name):\n",
    "       # Initialize the embedding model\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "        self.chroma_client = chromadb.Client()\n",
    "        self.collection = self.chroma_client.create_collection(name=collection_name)\n",
    "\n",
    "    # Method to populate the vector store with embeddings from a dataset\n",
    "    def populate_vectors(self, dataset):\n",
    "        # Select the text columns to concatenate\n",
    "        # title = dataset['train']['title_cleaned'][:1000]  # Limiting to 100 examples for the demo\n",
    "        recipe = dataset['train']['recipe_new'][:1000]\n",
    "        allergy = dataset['train']['allergy_type'][:1000]\n",
    "        ingredients = dataset['train']['ingredients_alternatives'][:1000]\n",
    "\n",
    "        # Concatenate the text from both columns\n",
    "        texts = [f\"{rep} {ingr} {alle}\" for rep, ingr,alle in zip(recipe, ingredients,allergy)]\n",
    "        for i, item in enumerate(texts):\n",
    "            embeddings = self.embedding_model.encode(item).tolist()\n",
    "            self.collection.add(embeddings=[embeddings], documents=[item], ids=[str(i)])\n",
    "\n",
    "    # # Method to search the ChromaDB collection for relevant context based on a query\n",
    "    def search_context(self, query, n_results=1):\n",
    "        query_embeddings = self.embedding_model.encode(query).tolist()\n",
    "        return self.collection.query(query_embeddings=query_embeddings, n_results=n_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset hosted on huggingface\n",
    "# dataset details - https://huggingface.co/datasets/Thefoodprocessor/recipe_new_with_features_full\n",
    "dataset = load_dataset('Thefoodprocessor/recipe_new_with_features_full')\n",
    "\n",
    "# create a vector embedding\n",
    "vector_store = VectorStore(\"embedding_vector\")\n",
    "vector_store.populate_vectors(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading gpt4all language model\n",
    "# load model Chat based model mistral-7b-openorca.gguf2.Q4_0.gguf\n",
    "# detail about gpt4all and model information - https://gpt4all.io/index.html\n",
    "model_name = 'mistral-7b-openorca.gguf2.Q4_0.gguf' \n",
    "model_path = Path.home() / '.cache' / 'gpt4all'\n",
    "model = GPT4All(model_name=model_name, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []\n",
    "# Define the chatbot response function connecting the history\n",
    "def chatbot_response(user_input):\n",
    "    global conversation_history\n",
    "    results = vector_store.search_context(user_input, n_results=1)\n",
    "    context = results['documents'][0] if results['documents'] else \"\"\n",
    "    conversation_history.append(f\"User: {user_input}\\nContext: {context}\\nBot:\")\n",
    "    response = model.generate(\"\\n\".join(conversation_history),temp=0)\n",
    "    conversation_history.append(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"What's cooking! Type 'exit' to end the conversation.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Ending the conversation. Happy meal!\")\n",
    "            break\n",
    "        response = chatbot_response(user_input)\n",
    "        print(f\"Diet_chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's cooking! Type 'exit' to end the conversation.\n",
      "Diet_chatbot:  I understand that you have some carrots and rice. It seems like you are looking for a recipe to use these ingredients in. Here's a suggestion:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of cooked brown or white rice (substitute with any other grain if desired)\n",
      "- 2 medium carrots, peeled and grated\n",
      "- 3 cloves garlic, minced\n",
      "- 1/4 cup chopped fresh cilantro or parsley (optional)\n",
      "- 1 tablespoon sesame oil or olive oil\n",
      "- 2 teaspoons soy sauce or tamari\n",
      "- Salt and pepper to taste\n",
      "\n",
      "Instructions:\n",
      "1. Cook the rice according to package instructions, then set aside.\n",
      "2. In a large skillet or wok, heat the oil over medium heat. Add the garlic and cook for about 30 seconds until fragrant but not browned.\n",
      "3. St\n",
      "Diet_chatbot:  I understand that you have some milk. Here's a dessert recipe suggestion for you:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup whole milk (substitute with any other type of milk if desired)\n",
      "- 2 tablespoons sugar\n",
      "- 1/4 teaspoon vanilla extract\n",
      "- Fresh fruit or toppings as desired (e.g., berries, nuts, chocolate chips)\n",
      "\n",
      "Instructions:\n",
      "1. In a blender or food processor, combine the milk, sugar, and vanilla extract. Blend until smooth and frothy.\n",
      "2. Pour the mixture into a glass or cup and serve immediately with your choice of fresh fruit or toppings.\n",
      "Ending the conversation. Happy meal!\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
